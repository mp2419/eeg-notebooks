{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "Clean Data\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AudioVisual_04_1.fif', 'AudioVisual_04_2.fif', 'AudioVisual_06_1.fif', 'AudioVisual_06_2.fif', 'ShapeVisual_01_1.fif', 'ShapeVisual_01_2.fif', 'ShapeVisual_02_2.fif', 'ShapeVisual_03_1.fif', 'ShapeVisual_03_2.fif', 'ShapeVisual_04_1.fif', 'ShapeVisual_04_2.fif', 'ShapeVisual_06_2.fif', 'ShapeVisual_07_2.fif', 'ShapeVisual_09_1.fif', 'ShapeVisual_10_1.fif', 'ShapeVisual_10_2.fif', 'ShapeVisual_11_1.fif', 'ShapeVisual_11_2.fif', 'ShapeVisual_12_1.fif', 'ShapeVisual_14_1.fif', 'ShapeVisual_14_2.fif', 'ShapeVisual_15_1.fif', 'ShapeVisual_15_2.fif', 'VibroVisual_06_1.fif', 'VibroVisual_02_2.fif', 'VibroVisual_03_1.fif', 'VibroVisual_03_2.fif']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import mne, os\n",
    "import json\n",
    "\n",
    "with open('C:\\\\Users\\\\matil\\\\Desktop\\\\FYP\\\\code_env\\\\eeg-notebooks\\\\FYP\\\\results_data\\\\Outliers_7030.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "keys_below_30 = []\n",
    "for key, values in data.items():\n",
    "    if all(value < 50 for value in values):\n",
    "        key = key.replace('.json', '.fif')\n",
    "        keys_below_30.append(key)\n",
    "\n",
    "to_add = ['VibroVisual_02_2.fif','VibroVisual_03_1.fif','VibroVisual_03_2.fif'] #'VibroVisual_10_2.fif',\n",
    "for i in to_add:\n",
    "    keys_below_30.append(i)\n",
    "\n",
    "print(keys_below_30)\n",
    "keys_below_30 = ['AudioVisual_04_1.fif', 'AudioVisual_04_2.fif', 'AudioVisual_06_1.fif', 'AudioVisual_06_2.fif',  'ShapeVisual_03_1.fif', 'ShapeVisual_03_2.fif', 'ShapeVisual_04_1.fif', 'ShapeVisual_04_2.fif', 'ShapeVisual_06_2.fif', 'VibroVisual_06_1.fif', 'VibroVisual_02_2.fif', 'VibroVisual_03_1.fif', 'VibroVisual_03_2.fif']\n",
    "\n",
    "# keys_below_30  = ['AudioVisual_04_1.fif', 'AudioVisual_04_2.fif', 'AudioVisual_06_1.fif', 'AudioVisual_06_2.fif',  'AudioVisual_15_2.fif', 'AudioVisual_15_1.fif',               'AudioVisual_14_1.fif', 'AudioVisual_14_2.fif', 'AudioVisual_17_1.fif', 'AudioVisual_17_2.fif',\n",
    "#              'ShapeVisual_03_1.fif', 'ShapeVisual_03_2.fif', 'ShapeVisual_06_2.fif',  'ShapeVisual_12_1.fif', 'ShapeVisual_14_1.fif', 'ShapeVisual_14_2.fif', 'ShapeVisual_17_1.fif', 'ShapeVisual_17_2.fif', \n",
    "#              'VibroVisual_10_2.fif','VibroVisual_02_2.fif','VibroVisual_10_1.fif','VibroVisual_02_1.fif','VibroVisual_03_1.fif','VibroVisual_03_2.fif', 'VibroVisual_17_1.fif', 'VibroVisual_17_2.fif'] # \n",
    "\n",
    "\n",
    "raw_folder = os.path.join(os.path.expanduser('~/'),'Desktop', 'FYP', 'code_env', 'eeg-notebooks','FYP', 'data_ordered', 'mne_raw')\n",
    "raw_files_all = [file for file in os.listdir(raw_folder) if file.endswith(\".fif\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "ERP for all raws, left n right\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matil\\Desktop\\FYP\\code_env\\eeg-notebooks\\FYP\\experiments\\eeg_analysis_lib.py:570: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "c:\\Users\\matil\\Desktop\\FYP\\code_env\\eeg-notebooks\\FYP\\experiments\\eeg_analysis_lib.py:606: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "from eeg_analysis_lib import erp_alltrials\n",
    "import mne\n",
    "\n",
    "mne.set_log_level(\"ERROR\")\n",
    "erp_alltrials(keys_below_30, mode= \"Audio\", rejection_th =1000, show_trials=False, arrow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matil\\Desktop\\FYP\\code_env\\eeg-notebooks\\FYP\\experiments\\eeg_analysis_lib.py:570: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "c:\\Users\\matil\\Desktop\\FYP\\code_env\\eeg-notebooks\\FYP\\experiments\\eeg_analysis_lib.py:606: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "from eeg_analysis_lib import erp_alltrials\n",
    "import mne\n",
    "erp_alltrials(keys_below_30, mode= \"Vibro\", rejection_th =1000, show_trials=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matil\\Desktop\\FYP\\code_env\\eeg-notebooks\\FYP\\experiments\\eeg_analysis_lib.py:570: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
      "c:\\Users\\matil\\Desktop\\FYP\\code_env\\eeg-notebooks\\FYP\\experiments\\eeg_analysis_lib.py:606: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "erp_alltrials(keys_below_30, mode= \"Shape\", rejection_th =1000, show_trials=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "Audio 1 Participant All Plots\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matil\\miniconda3\\envs\\eeg-notebooks\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "import os, mne\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from eeg_analysis_lib import create_raw_object, extract_direction_evoked\n",
    "\n",
    "mne.set_log_level(\"ERROR\")\n",
    "epochs = {\"left\": [], \"right\": []}\n",
    "raw_path = os.path.join(os.path.expanduser('~/'), 'Desktop', 'FYP', 'code_env', 'eeg-notebooks', 'FYP', 'data_ordered', 'mne_raw', 'AudioVisual_03_1.fif')\n",
    "raw  = mne.io.read_raw_fif(raw_path, preload=True)\n",
    "epochs[\"left\"], epochs[\"right\"] = extract_direction_evoked(raw, plot_display=True)\n",
    "import scipy.stats as stats\n",
    "evokeds = dict(\n",
    "        left=list(epochs[\"left\"].iter_evoked()),\n",
    "        right=list(epochs[\"right\"].iter_evoked()),\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.axhline(0, color='black', linewidth=0.5)\n",
    "ax.axvline(0, color='black',linestyle='--', linewidth=0.5)\n",
    "for condition, evoked_list in evokeds.items():\n",
    "    # Stack the data for all trials in a 2D array (time x trials)\n",
    "    data_all_trials = np.vstack([evoked.data for evoked in evoked_list])\n",
    "    \n",
    "    # Compute mean and standard error across trials\n",
    "    mean = np.mean(data_all_trials, axis=0)\n",
    "    sem = stats.sem(data_all_trials, axis=0)\n",
    "    \n",
    "    # Plot mean response\n",
    "    ax.plot(evoked_list[0].times, mean, label=f\"'{condition}' - Mean\")\n",
    "    \n",
    "    # Plot standard error as shading\n",
    "    ax.fill_between(evoked_list[0].times, mean - sem, mean + sem, alpha=0.2, label=f\"'{condition}'- SEM\")\n",
    "    ax.tick_params(axis='both', which='both', labelsize=16)  # Increase tick label size for both x and y axes\n",
    "\n",
    "# Add labels, title and legend\n",
    "\n",
    "ax.set_xlabel(\"Time from event (s)\", fontsize=18)\n",
    "ax.set_ylabel(\"Amplitude (uV)\", fontsize=18)\n",
    "ax.set_title(\"ERP - Audio trial 1, participant 03\", fontsize=20, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('C:\\\\Users\\\\matil\\\\Desktop\\\\FYP\\\\code_env\\\\eeg-notebooks\\\\FYP\\\\results_data\\\\svg\\\\ERP_audio03_1.svg', format='svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "Vibro 1 Participant All Plots\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matil\\miniconda3\\envs\\eeg-notebooks\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "import os, mne\n",
    "from eeg_analysis_lib import create_raw_object, extract_direction_evoked\n",
    "\n",
    "mne.set_log_level(\"ERROR\")\n",
    "epochs = {\"left\": [], \"right\": []}\n",
    "raw_path = os.path.join(os.path.expanduser('~/'), 'Desktop', 'FYP', 'code_env', 'eeg-notebooks', 'FYP', 'data_ordered', 'mne_raw', 'VibroVisual_03_1.fif')\n",
    "raw  = mne.io.read_raw_fif(raw_path, preload=True)\n",
    "raw  = mne.io.read_raw_fif(raw_path, preload=True)\n",
    "epochs[\"left\"], epochs[\"right\"] = extract_direction_evoked(raw, plot_display=True)\n",
    "import scipy.stats as stats\n",
    "evokeds = dict(\n",
    "        left=list(epochs[\"left\"].iter_evoked()),\n",
    "        right=list(epochs[\"right\"].iter_evoked()),\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.axhline(0, color='black', linewidth=0.5)\n",
    "ax.axvline(0, color='black',linestyle='--', linewidth=0.5)\n",
    "for condition, evoked_list in evokeds.items():\n",
    "    # Stack the data for all trials in a 2D array (time x trials)\n",
    "    data_all_trials = np.vstack([evoked.data for evoked in evoked_list])\n",
    "    \n",
    "    # Compute mean and standard error across trials\n",
    "    mean = np.mean(data_all_trials, axis=0)\n",
    "    sem = stats.sem(data_all_trials, axis=0)\n",
    "    \n",
    "    # Plot mean response\n",
    "    ax.plot(evoked_list[0].times, mean, label=f\"'{condition}' - Mean\")\n",
    "    \n",
    "    # Plot standard error as shading\n",
    "    ax.fill_between(evoked_list[0].times, mean - sem, mean + sem, alpha=0.2, label=f\"'{condition}'- SEM\")\n",
    "    ax.tick_params(axis='both', which='both', labelsize=16)  # Increase tick label size for both x and y axes\n",
    "\n",
    "# Add labels, title and legend\n",
    "\n",
    "ax.set_xlabel(\"Time from event (s)\", fontsize=18)\n",
    "ax.set_ylabel(\"Amplitude (uV)\", fontsize=18)\n",
    "ax.set_title(\"ERP - Vibro trial 1, participant 03\", fontsize=20, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('C:\\\\Users\\\\matil\\\\Desktop\\\\FYP\\\\code_env\\\\eeg-notebooks\\\\FYP\\\\results_data\\\\svg\\\\ERP_vibro03_1.svg', format='svg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "Shape 1 Participant  All Plots\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matil\\miniconda3\\envs\\eeg-notebooks\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "import os, mne\n",
    "from eeg_analysis_lib import create_raw_object, extract_direction_evoked\n",
    "\n",
    "mne.set_log_level(\"ERROR\")\n",
    "epochs = {\"left\": [], \"right\": []}\n",
    "raw_path = os.path.join(os.path.expanduser('~/'), 'Desktop', 'FYP', 'code_env', 'eeg-notebooks', 'FYP', 'data_ordered', 'mne_raw', 'ShapeVisual_03_1.fif')\n",
    "raw  = mne.io.read_raw_fif(raw_path, preload=True)\n",
    "epochs[\"left\"], epochs[\"right\"] = extract_direction_evoked(raw, plot_display=True)\n",
    "import scipy.stats as stats\n",
    "evokeds = dict(\n",
    "        left=list(epochs[\"left\"].iter_evoked()),\n",
    "        right=list(epochs[\"right\"].iter_evoked()),\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.axhline(0, color='black', linewidth=0.5)\n",
    "ax.axvline(0, color='black',linestyle='--', linewidth=0.5)\n",
    "for condition, evoked_list in evokeds.items():\n",
    "    # Stack the data for all trials in a 2D array (time x trials)\n",
    "    data_all_trials = np.vstack([evoked.data for evoked in evoked_list])\n",
    "    \n",
    "    # Compute mean and standard error across trials\n",
    "    mean = np.mean(data_all_trials, axis=0)\n",
    "    sem = stats.sem(data_all_trials, axis=0)\n",
    "    \n",
    "    # Plot mean response\n",
    "    ax.plot(evoked_list[0].times, mean, label=f\"'{condition}' - Mean\")\n",
    "    \n",
    "    # Plot standard error as shading\n",
    "    ax.fill_between(evoked_list[0].times, mean - sem, mean + sem, alpha=0.2, label=f\"'{condition}'- SEM\")\n",
    "    ax.tick_params(axis='both', which='both', labelsize=16)  # Increase tick label size for both x and y axes\n",
    "\n",
    "# Add labels, title and legend\n",
    "\n",
    "ax.set_xlabel(\"Time from event (s)\", fontsize=18)\n",
    "ax.set_ylabel(\"Amplitude (uV)\", fontsize=18)\n",
    "ax.set_title(\"ERP - Shape trial 1, participant 03 \", fontsize=20, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('C:\\\\Users\\\\matil\\\\Desktop\\\\FYP\\\\code_env\\\\eeg-notebooks\\\\FYP\\\\results_data\\\\svg\\\\ERP_shape03_1.svg', format='svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
